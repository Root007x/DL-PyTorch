{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## Data_Setup"
      ],
      "metadata": {
        "id": "6uLJ6RQ7UFwO"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "89zBgnPnQwIh",
        "outputId": "4bc6ba67-a0c8-42d9-811d-379f3e8c0998"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing module/data_setup.py\n"
          ]
        }
      ],
      "source": [
        "## data-setup\n",
        "%%writefile module/data_setup.py\n",
        "\n",
        "import os\n",
        "import torch\n",
        "import torchvision\n",
        "from torchvision import datasets, transforms\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "def create_dataloader(\n",
        "        train_dir : str,\n",
        "        test_dir : str,\n",
        "        transform : transforms.Compose,\n",
        "        batch_size : int,\n",
        "        num_workers : int = os.cpu_count()):\n",
        "\n",
        "    train_data = datasets.ImageFolder(train_dir, transform = transform)\n",
        "    test_data = datasets.ImageFolder(test_dir, transfomr = transform)\n",
        "\n",
        "    class_names = train_data.classes\n",
        "\n",
        "    train_dataloader = DataLoader(\n",
        "        train_data,\n",
        "        batch_size = batch_size,\n",
        "        shuffle = True,\n",
        "        num_workers = num_workers,\n",
        "        pin_memory = True\n",
        "    )\n",
        "\n",
        "    test_dataloader = DataLoader(\n",
        "        test_data,\n",
        "        batch_size = batch_size,\n",
        "        shuffle = False,\n",
        "        num_workers = num_workers,\n",
        "        pin_memory = True\n",
        "    )\n",
        "\n",
        "    return train_dataloader, test_dataloader, class_names\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Engine setup"
      ],
      "metadata": {
        "id": "x_p43lhiRJAt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile module/engine_setup.py\n",
        "\n",
        "\n",
        "import torch\n",
        "from tqdm.auto import tqdm\n",
        "from typing import Dict, List, Tuple\n",
        "\n",
        "# train_step()\n",
        "def train_step(model : torch.nn.Module,\n",
        "               dataloader : torch.utils.data.DataLoader,\n",
        "               loss_fn : torch.nn.Module,\n",
        "               optimizer : torch.optim.Optimizer,\n",
        "               device : torch.device) -> Tuple[float, float]:\n",
        "\n",
        "\n",
        "    model.train() # Train mode\n",
        "    train_loss, train_acc = 0, 0\n",
        "\n",
        "    for batch, (x_train,y_train) in enumerate(dataloader):\n",
        "\n",
        "        x_train, y_train = x_train.to(device), y_train.to(device)\n",
        "\n",
        "        # 1. Forward pass\n",
        "        y_pred = model(x_train) # logits\n",
        "\n",
        "        # 2. loss\n",
        "        loss = loss_fn(y_pred, y_train)\n",
        "        train_loss += loss.item()\n",
        "\n",
        "        # 3. Optimizer\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # 4. backporpagation\n",
        "        loss.backward()\n",
        "\n",
        "        # 5. step optimizer\n",
        "        optimizer.step()\n",
        "\n",
        "        # Calculate accuracy\n",
        "        y_pred_class = torch.argmax(torch.softmax(y_pred,dim = 1), dim = 1)\n",
        "        train_acc += (y_pred_class == y_pred).sum().item()/len(y_pred)\n",
        "\n",
        "    train_loss = train_loss / len(dataloader)\n",
        "    train_acc = train_acc / len(dataloader)\n",
        "    return train_loss, train_acc\n",
        "\n",
        "\n",
        "# Test_step()\n",
        "def test_step(model : torch.nn.Module,\n",
        "              dataloader : torch.utils.data.DataLoader,\n",
        "              loss_fn : torch.nn.Module,\n",
        "              device : torch.device) -> Tuple[float, float]:\n",
        "\n",
        "\n",
        "    model.eval() # Eval mode\n",
        "    with torch.inference_mode():\n",
        "        test_loss, test_acc = 0, 0\n",
        "\n",
        "        for batch, (x_test, y_tess) in enumerate(dataloader):\n",
        "\n",
        "            x_test, y_test = x_test.to(device), y_test.to(device)\n",
        "\n",
        "            # 1. forward pass\n",
        "            test_pred = model(x_test)\n",
        "\n",
        "            # 2. loss\n",
        "            loss = loss_fn(test_pred,y_test)\n",
        "            test_loss += loss.item()\n",
        "\n",
        "            # calculate accuracy\n",
        "            test_pred_labels = test_pred.argmax(dim =  1)\n",
        "            test_acc += (test_pred_labels == y_test).sum().item()/len(test_pred_labels)\n",
        "\n",
        "    test_loss += test_loss / len(dataloader)\n",
        "    test_acc += test_acc / len(dataloader)\n",
        "    return test_loss, test_acc\n",
        "\n",
        "\n",
        "# Train\n",
        "def train(model : torch.nn.Module,\n",
        "          train_dataloader : torch.utils.data.DataLoader,\n",
        "          test_dataloader : torch.utils.data.DataLoader,\n",
        "          optimizer : torch.optim.Optimizer,\n",
        "          loss_fn : torch.nn.Module,\n",
        "          epochs : int,\n",
        "          device : torch.device) -> Dict[str, list]:\n",
        "\n",
        "    results = {\"train_loss\" : [],\n",
        "                \"train_acc\" : [],\n",
        "                \"test_loss\" : [],\n",
        "                \"test_acc\" : []}\n",
        "\n",
        "    for epoch in tqdm(range(epochs)):\n",
        "\n",
        "        train_loss, train_acc = train_step(model = model,\n",
        "                                            dataloader = train_dataloader,\n",
        "                                            loss_fn = loss_fn,\n",
        "                                            optimizer = optimizer,\n",
        "                                            device = device)\n",
        "\n",
        "        test_loss, test_acc = test_step(model = model,\n",
        "                                        dataloader = test_dataloader,\n",
        "                                        loss_fn = loss_fn,\n",
        "                                        device = device)\n",
        "\n",
        "\n",
        "        print(\n",
        "            f\"Epoch: {epoch+1} | \"\n",
        "            f\"train_loss: {train_loss:.4f} | \"\n",
        "            f\"train_acc: {train_acc:.4f} | \"\n",
        "            f\"test_loss: {test_loss:.4f} | \"\n",
        "            f\"test_acc: {test_acc:.4f}\"\n",
        "        )\n",
        "\n",
        "        results[\"train_loss\"].append(train_loss)\n",
        "        results[\"train_acc\"].append(train_acc)\n",
        "        results[\"test_loss\"].append(test_loss)\n",
        "        results[\"test_acc\"].append(test_acc)\n",
        "\n",
        "        return results"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F7Zz0rGXUaTW",
        "outputId": "c5425e6a-c1ef-4271-991f-87bb768c7287"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting module/engine_setup.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "4Fztbh15WoXb"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}